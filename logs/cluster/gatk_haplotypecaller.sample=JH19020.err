Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Select jobs to execute...

[Sat Oct  9 20:41:14 2021]
rule gatk_haplotypecaller:
    input: /fs03/pg32/zarul/results/preprocessing/gatk_applybqsr/JH19020_recal.bam, /fs03/pg32/zarul/results/preprocessing/gatk_applybqsr/JH19020_recal.bai, /fs03/pg32/zarul/results/GRCh38_full_analysis_set_plus_decoy_hla.fa, /fs03/ie79/db/gatk_bundle_db/dbsnp_138.hg38.vcf.gz, input_folder/exome.bed
    output: /fs03/pg32/zarul/results/preprocessing/gatk_haplotypecaller/JH19020_variants.g.vcf.gz, /fs03/pg32/zarul/results/preprocessing/gatk_haplotypecaller/JH19020_variants.g.vcf.gz.tbi
    log: /fs03/pg32/zarul/results/log/preprocessing/gatk_haplotypecaller/JH19020.log
    jobid: 0
    wildcards: sample=JH19020
    resources: mem_mb=31614, disk_mb=31614, tmpdir=/tmp

Activating conda environment: /projects/pg32/WES_preliminary_analyses/.snakemake/conda/60b2de714ad41663a24ed17709833ece
[Sat Oct  9 21:13:58 2021]
Finished job 0.
1 of 1 steps (100%) done
