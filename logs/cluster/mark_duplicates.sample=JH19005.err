Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Select jobs to execute...

[Sat Oct  9 20:41:02 2021]
rule mark_duplicates:
    input: /fs03/pg32/zarul/results/merge_bamfiles/JH19005.bam
    output: /fs03/pg32/zarul/results/marked_dup/JH19005.bam, /fs03/pg32/zarul/results/marked_dup/JH19005.metrics.txt
    log: /fs03/pg32/zarul/results/log/mark_duplicates/JH19005.log
    jobid: 0
    wildcards: sample=JH19005
    resources: mem_mb=8325, disk_mb=8325, tmpdir=/tmp

Activating conda environment: /projects/pg32/WES_preliminary_analyses/.snakemake/conda/ff944c3fd317023ffbdbe7a022133507
[Sat Oct  9 20:59:38 2021]
Finished job 0.
1 of 1 steps (100%) done
